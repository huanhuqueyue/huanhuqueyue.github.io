<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: information-bottleneck - Queyue</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Queyue"><meta name="msapplication-TileImage" content="/img/logome.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Queyue"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Queyue"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="Queyue"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="Haitao Mao"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Queyue","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Haitao Mao"},"description":""}</script><link rel="icon" href="/img/logome.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="text:Queyue&#039;s Home" alt="Queyue" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">information-bottleneck</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-22T11:37:00.000Z" title="2020-12-22T11:37:00.000Z">2020-12-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-12-23T14:53:04.872Z" title="2020-12-23T14:53:04.872Z">2020-12-23</time></span><span class="level-item">14 minutes read (About 2025 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/22/How-Neural-Networks-Extrapolate/">How Neural Networks Extrapolate</a></h1><div class="content"><p>ICLR2021评分最高的文章，keyulu xu是一个研究GNN原理的学者，从how powerful GNN is开始关注，的确做了很多不错的工作。</p>
<h2 id="abstraction"><a href="#abstraction" class="headerlink" title="abstraction"></a>abstraction</h2><p>我们的任务是什么？Extrapolate 推断</p>
<p>在训练集的数据分布之外，模型能做到多少的拓展性。</p>
<p>和一般研究的train和test的泛化误差之间存在什么区别？</p>
<p>train和test我们一般认为是来自同一个分布的，Extrapolate的测试test一般会是一个比当前任务更加复杂的问题，难度会更大。  DP就是Extrapolate的问题</p>
<p>相关工作发现的一些现象：</p>
<ul>
<li>MLP在简单的任务上Extrapolate的效果都不是很好</li>
<li>GNN可以在复杂的任务上Extrapolate很好</li>
</ul>
<p>论文当中发现的一些现象：</p>
<ul>
<li>relu+MLP会快速的在训练数据分布外收敛为线性（不管方向是什么）  这意味着MLP很难对非线性进行泛化</li>
<li>我们证明了MLP在一些sufficient的线性条件下收敛的效果比较好</li>
<li>为什么GNN Extrapolate的能力强，因为GNN能学到一些非线性（这些非线性和任务相关，比如图的结构等等）</li>
</ul>
<h2 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h2><p>研究问题的出发点：为什么GNN+MLP可以在复杂的task上Extrapolate的很好，但是MLP不行</p>
<p>为什么理论上MLP有无限强的拟合能力，但实际上做不到？</p>
<p>因为受到梯度下降的限制。</p>
<p>MLP究竟拟合能力是什么样子的？</p>
<ul>
<li><p>asbtract 提到的收敛到线性</p>
</li>
<li><p>两层的MLP （假设是无限宽的）  收敛到稍微outside一点分布的信息</p>
</li>
<li><p>relu MLP的Extrapolate能力不是很多个的线性的空间而是最后收敛到 一个线性空间中</p>
</li>
<li><p>MLP泛化的好需要满足的条件  任务是线性的并且训练分布满足特定的几何形状</p>
</li>
</ul>
<p><img src="./../img/How-Neural-Networks-Extrapolate/fig1.PNG" alt="text"></p>
<p>Extrapolate究竟是什么？</p>
<p>按照规则来说，Extrapolate就是DP，惊不惊喜，DP其实有点类似数学归纳法，定义一个规则可以靠累加的方式达到。</p>
<p>DP的关键是什么？</p>
<p>线性和非线性的结合 ，就拿下图中间的例子作为示例  min就是非线性的部分，穷举所有的方法就是一个线性的过程</p>
<p><img src="./../img/How-Neural-Networks-Extrapolate/fig2.PNG" alt="text"></p>
<p>得出结论，求解一个Extrapolate问题既需要线性，也需要非线性。</p>
<p>如何得到非线性：</p>
<ul>
<li>设计合适的非线性结构 比如min</li>
<li>根据结构和领域知识设计特定的结构</li>
</ul>
<p>为什么要用GNN，因为MLP只能在训练分布内非线性，而在分布外快速收敛为线性</p>
<h3 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h3><p><img src="./../img/How-Neural-Networks-Extrapolate/Preliminary.PNG" alt="text"></p>
<p>还是先把符号表示的定义给出来</p>
<h3 id="3-How-Feedforward-Neural-Networks-Extrapolate"><a href="#3-How-Feedforward-Neural-Networks-Extrapolate" class="headerlink" title="3 How Feedforward Neural Networks Extrapolate"></a>3 How Feedforward Neural Networks Extrapolate</h3><p>回想relu的性质，和有界的激活函数不同，函数是一个半开放的线性函数。</p>
<p>在实验中发现了不管train distribution是什么样子，使用线性回归拟合R²的置信度都达到99%</p>
<p>怎么衡量出的这种性质？</p>
<p>观察使用正切核，梯度下降的网络偏差</p>
<p>正切核条件：</p>
<p>网络无限宽，随机初始化，适当剪切，训练步长无限小，平方损失的函数使用GD来训练的全连接网络</p>
<p><img src="./../img/How-Neural-Networks-Extrapolate/fig4.PNG" alt="text"></p>
<p>图4实验主要证明了 </p>
<ol>
<li>对于linear的目标函数，拟合的效果比较好</li>
<li>拟合linear的目标函数  但是会固定部分的向量维度，或者负数 从实验中我们可以看出来，不固定任何方向效果是最好的，固定方向或者增加neg的数量都会限制模型的extrapolate</li>
</ol>
<p>既然对linear函数拟合的比较好，但其实也是有条件的哈，这和data分布的质心是相关联额</p>
<p><img src="./../img/How-Neural-Networks-Extrapolate/theorem5.PNG" alt="text"></p>
<p>一言以蔽之，就是对于一个relu两层的全连接层，如果S能组合出任意的方向，那么在训练量足够充分的情况下，对linear分布有比较好的拟合能力</p>
<p>实验结果如下图</p>
<p><img src="./../img/How-Neural-Networks-Extrapolate/fig3.PNG" alt="text"></p>
<p>第二个图不好用的主要原始是方向问题，在上面的结论中k&gt;0 所以在另一侧出现了偏差</p>
<p>如上理论不仅给出了如上的保障，还可以解释为什么模型出现偏差的原因，如果我们的数据分布不是全面的，偏向一个方向，就会出现fig3的关联，比如兔子和草地之间的关联信息</p>
<p>聊完Relu激活，其他的激活方式呢</p>
<p><img src="./../img/How-Neural-Networks-Extrapolate/fig5.PNG" alt="text"></p>
<ul>
<li>tanh函数对于各种超参的适应性都比较好  适用于tanh类型的目标</li>
<li>cosine  甚至对训练集的拟合能力都不是很好</li>
<li>二次激活，深层次效果不好   层次越深越倾向于拟合高阶的曲线</li>
</ul>
<p><strong>像sigmoid  tanh这种激活函数的方法分别能拟合对应的分布  想当于mlp加线性的变体</strong></p>
<h2 id="4-How-Graph-Neural-Networks-Extrapolate"><a href="#4-How-Graph-Neural-Networks-Extrapolate" class="headerlink" title="4 How Graph Neural Networks Extrapolate"></a>4 How Graph Neural Networks Extrapolate</h2><p>整体思想：linear的MLP需要和non-linear的模块相结合  MLP能对GNN的内容align</p>
<p>在介绍NLP之前，回答之前的基本问题</p>
<p><img src="./../img/How-Neural-Networks-Extrapolate/fig2.PNG" alt="text"></p>
<p>上面的例子是我们的迪杰斯特拉算法，如果使用sun的方法 MLP就要拟合非线性的部分，通过上面的理论来说是不太可能的，所以使用min作为聚合方式是比较合理的。（这里聊的只是一个demo）</p>
<p>依次类推，我们的GNN是不是可以代替min完成非线性的任务呢，毕竟任务不能都像这里一样特定有这样min的一个解 </p>
<p>关于具体做法，我们这里还是引用原文8</p>
<p>For some tasks, it may be easier to change the input representation (Fig. 2b). Sometimes, we can decompose the target function f as f = g  h into an embedding h and a “simpler” target function g that our model can extrapolate well. If we can identify h from domain knowledge, then the model only needs to learn g [Corso et al., 2020, Lample and Charton, 2020, Zhang et al., 2019]. Alternatively, h may be obtained via representation learning with unlabeled out-of-distribution data from X n D [Chen et al., 2020, Devlin et al., 2019, Hu et al., 2020, Peters et al., 2018], which might explain why pre-trained representations such as BERT can improve out-of-distribution robustness [Hendrycks et al., 2020]. Linear algorithmic alignment explains successful extrapolation in the literature and suggests that extrapolation is hard in general: encoding appropriate non-linearity often requires domain expertise and/or model search. Next, we provide theoretical and empirical support for the linear algorithmic alignment hypothesis. While we focus on GNNs, our insights apply to other networks too.</p>
<p>对于GNN的理论保证</p>
<ol>
<li>加和的aggregate方式是学不会max  degree问题的</li>
<li>max的处理效果会比较好  这里也有理论theory的保证，不多说了<ul>
<li>和MLP一样，数据要保证多样性</li>
<li>max node的数目和图的种类具有多样性</li>
</ul>
</li>
</ol>
<p><img src="./../img/How-Neural-Networks-Extrapolate/fig6.PNG" alt="text"></p>
<p><img src="./../img/How-Neural-Networks-Extrapolate/fig7.PNG" alt="text"></p>
<p>对于不同分布学出来的效果不同。 对于shortest path的问题，对于稀疏和稠密的图都会出现退化的现象</p>
<p><strong>好的表达也会增大模型的能力</strong>   这里模型通过计算复杂的特征（规则）来优化模型的泛化能力，避免MLP对非线性的拟合</p>
<h2 id="和其他领域的联系"><a href="#和其他领域的联系" class="headerlink" title="和其他领域的联系"></a>和其他领域的联系</h2><ul>
<li><p>DA</p>
<p>DA在训练的时候使用测试集的数据增加非线性 增加模型的非线性能力</p>
</li>
<li><p>self supervise</p>
<p>BERT大量的语料信息提供了大量的额外的非线性的分布i锡尼希</p>
</li>
<li><p>Invariant model</p>
<p>因果推理来找到模型当中的不变量  能增大训练数据集能学到的范围</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-21T12:43:55.000Z" title="2020-12-21T12:43:55.000Z">2020-12-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-12-23T14:53:00.318Z" title="2020-12-23T14:53:00.318Z">2020-12-23</time></span><span class="level-item">11 minutes read (About 1686 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/21/Graph-information-bottleneck/">Graph information bottleneck</a></h1><div class="content"><p>这篇本来是昨天写完了，结果昨晚电脑硬件升级，全都没了呜呜呜</p>
<h2 id="abstraction"><a href="#abstraction" class="headerlink" title="abstraction"></a>abstraction</h2><p>图神经网络为什么work？</p>
<p>因为图神经网络能同时学到特征的信息和网络结构的信息</p>
<p>图神经网络有什么问题？</p>
<p>容易受到攻击，对数据的依赖性比较强</p>
<p>提出解决方案，使用IB理论兼顾表达能力和鲁棒性，<strong>学到和target y充足的 最小的互信息量 同时限制和X的互信息表达</strong></p>
<p>图网络算IB有什么不同？</p>
<ol>
<li>图数据不能满足iid的独立同分布   数据之前存在关联</li>
<li>输入数据有两种 邻接矩阵和特征信息   邻接矩阵信息还是离散的稀疏的，加入regular进行衡量</li>
</ol>
<h2 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h2><p>图网络容易受到攻击的来源？</p>
<p>图网络一般会采样邻居信息，但是邻居信息很多是没用的，信息传递的机制会造成大量噪声</p>
<p>什么是我们期待的好的表达？</p>
<p>![text](./../img/Graph information bottleneck/fig1.PNG)</p>
<p>鼓励和Y的互信息最大化，和X的互信息最小化</p>
<p>如何衡量互信息？遇到的问题</p>
<ol>
<li>图数据不能满足iid的独立同分布   数据之前存在关联</li>
<li>输入数据有两种 邻接矩阵和特征信息   邻接矩阵信息还是离散的稀疏的，加入regular进行衡量</li>
</ol>
<p>为了解决上述问题</p>
<ul>
<li>增加局部性假设（其实感觉这一点所有的GNN都在用）</li>
<li>层次化的去学习两种输入的信息（最后的数据流图画的有点像LSTM）</li>
<li>增加采样方法来增加模型的鲁棒性（也是为了好算分布）</li>
</ul>
<h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>![text](./../img/Graph information bottleneck/notion.PNG)</p>
<p>描述算法之前还是照例把符号系统放在系统</p>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>解决两个问题：</p>
<ul>
<li><p>如何同时学习两种输入的</p>
</li>
<li><p>如何衡量输入和输出的互信息的大小</p>
</li>
<li><p>如何把采样加入到模型当中</p>
</li>
</ul>
<p>![text](./../img/Graph information bottleneck/fig2.PNG)</p>
<p>首先先来最关键的8，我们的优化函数<br>$$<br>\min <em>{\mathbb{P}\left(Z</em>{X}^{(L)} \mid \mathcal{D}\right) \in \Omega} \operatorname{GIB}<em>{\beta}\left(\mathcal{D}, Y ; Z</em>{X}^{(L)}\right) \triangleq\left[-I\left(Y ; Z_{X}^{(L)}\right)+\beta I\left(\mathcal{D} ; Z_{X}^{(L)}\right)\right]<br>$$<br>这样我们的IB目标就很明确了，也是最核心idea的公式表达</p>
<p>然后介绍tricks，也就是我们如何进行近似得到最优解</p>
<h3 id="local-dependence假设"><a href="#local-dependence假设" class="headerlink" title="local dependence假设"></a>local dependence假设</h3><p>为什么要有这个假设？</p>
<p>如果想知道图中一个节点的全部信息，那就要考虑到所有节点。</p>
<p>近似：使用local几阶的节点表示节点的context信息（这也就衍生除了对比学习中经常提到的local patch和global信息的对比）</p>
<h3 id="IB上下界近似"><a href="#IB上下界近似" class="headerlink" title="IB上下界近似"></a>IB上下界近似</h3><p>对于深层网络直接进行近似难度很大   我们选用近似 和Y互信息的下界和X互信息的上界（想当于是最坏的情况）<br>$$<br>I\left(Y ; Z_{X}^{(L)}\right) \geq 1+\mathbb{E}\left[\log \frac{\prod_{v \in V} \mathbb{Q}<em>{1}\left(Y</em>{v} \mid Z_{X, v}^{(L)}\right)}{\mathbb{Q}<em>{2}(Y)}\right]+\mathbb{E}</em>{\mathbb{P}(Y) \mathbb{P}\left(Z_{X}^{(L)}\right)}\left[\frac{\prod_{v \in V} \mathbb{Q}<em>{1}\left(Y</em>{v} \mid Z_{X, v}^{(L)}\right)}{\mathbb{Q}_{2}(Y)}\right]<br>$$<br>Q2就是我们经常用的建议分布</p>
<p>$$<br>I\left(\mathcal{D} ; Z_{X}^{(L)}\right) \leq I\left(\mathcal{D} ;\left{Z_{X}^{(l)}\right}<em>{l \in S</em>{X}} \cup\left{Z_{A}^{(l)}\right}<em>{l \in S</em>{A}}\right) \leq \sum_{l \in S_{A}} \mathrm{AIB}^{(l)}+\sum_{l \in S_{X}} \mathrm{XIB}^{(l)}<br>$$</p>
<p>X代表GNN中的特征   A代表GNN中的邻接矩阵信息  Sx是l层之前的互信息   Sa是l层之后的互信息<br>$$<br>\mathrm{AIB}^{(l)}=\mathbb{E}\left[\log \frac{\mathbb{P}\left(Z_{A}^{(l)} \mid A, Z_{X}^{(l-1)}\right)}{\mathbb{Q}\left(Z_{A}^{(l)}\right)}\right], \mathrm{XIB}^{(l)}=\mathbb{E}\left[\log \frac{\mathbb{P}\left(Z_{X}^{(l)} \mid Z_{X}^{(l-1)}, Z_{A}^{(l)}\right)}{\mathbb{Q}\left(Z_{X}^{(l)}\right)}\right]<br>$$<br>A和X采用相同的变分（建议分布）</p>
<p>综上，我们的建模目标变为<br>$$<br>\mathbb{P}\left(Z_{A}^{(l)} \mid Z_{X}^{(l-1)}, A\right) \text { and } \mathbb{P}\left(Z_{X}^{(l)} \mid Z_{X}^{(l-1)}, Z_{A}^{(l)}\right)<br>$$<br>确定了所有的近似目标，来看最后的求解过程，注意在求解过程中，我们使用的参考模型是GAT（比较方便利用attention参数采样）</p>
<p>![text](./../img/Graph information bottleneck/algorithm.PNG)</p>
<p>算法还是比较简单，我们就不强调所有的位置了，挑一些重点来说</p>
<ul>
<li><p>neighbour sample的轮数和GAT当中multi head的效果类似</p>
</li>
<li><p>下一层X特征的产生是由上一轮产生的高斯分布生成的<br>$$<br>\hat{Z}<em>{X, v}^{(l)}=\mu</em>{v}^{(l)}+\sigma_{v}^{(l)} \odot z<br>$$</p>
</li>
<li><p>采样让模型拓扑模型不能完全决定A的内容，需要进行sample</p>
</li>
<li><p>上一轮的特征会决定这一轮的采样概率大小</p>
</li>
</ul>
<p>![text](./../img/Graph information bottleneck/algorithm2.PNG)</p>
<p>为什么训练的过程也要搞得这么奇怪？</p>
<p>为了在训练的时候知道各种分布，方便最后算loss计算的时候好计算</p>
<p>AIB如何进行描述？<br>$$<br>\begin{aligned}<br>\widehat{\mathrm{AIB}<em>{\mathrm{C}}}^{(l)} &amp;=\sum</em>{v \in V, t \in[\mathcal{T}]} \mathrm{KL}\left(\operatorname{Cat}\left(\phi_{v t}^{(l)}\right) | \operatorname{Cat}\left(\frac{1}{\left|V_{v t}\right|}\right)\right) \<br>\widehat{\mathrm{AIB}<em>{\mathrm{B}}}^{(l)} &amp;=\sum</em>{v \in V, t \in[T]} \mathrm{KL}\left(\text { Bernoulli }\left(\phi_{v t}^{(l)}\right) | \operatorname{Bernoulli}(\alpha)\right)<br>\end{aligned}<br>$$<br>我们简化A的采样为均匀采样，伯努利分布会增加一个α（是一个可以调节的超参数）</p>
<p>$$<br>\widehat{\mathrm{XIB}}^{(l)}=\log \frac{\mathbb{P}\left(Z_{X}^{(l)} \mid Z_{X}^{(l-1)}, Z_{A}^{(l)}\right)}{\mathbb{Q}\left(Z_{X}^{(l)}\right)}=\sum_{v \in V}\left[\log \Phi\left(Z_{X, v}^{(l)} ; \mu_{v}, \sigma_{v}^{2}\right)-\log \left(\sum_{i=1}^{m} w_{i} \Phi\left(Z_{X, v}^{(l)} ; \mu_{0, i}, \sigma_{0, i}^{2}\right)\right)\right]<br>$$<br>X特征的初始分布被认为为混合高斯分布  （参量都自己学）  Zx的表示参量在训练的时候已经学到了。<strong>这里我们没有去思考为什么要这么做  这么生成新的分布真的合理吗</strong></p>
<p>和Y的分布计算：<br>$$<br>\mathbb{Q}<em>{1}\left(Y</em>{v} \mid Z_{X, v}^{(L)}\right)=\operatorname{Cat}\left(Z_{X, v}^{(L)} W_{\text {out }}\right)<br>$$</p>
<p>$$<br>I\left(Y ; Z_{X}^{(L)}\right) \rightarrow-\sum_{v \in V} \text { Cross-Entropy }\left(Z_{X, v}^{(L)} W_{\text {out }} ; Y_{v}\right)<br>$$</p>
<p>说实话，这个简化看起来虽然还比较合理，但也有点太简单了8，我们可以简单的当作是主目标就好了。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>对IB的利用可能不一定正确8   </p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/logome.jpg" alt="悫躍"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">悫躍</p><p class="is-size-6 is-block">冬天太冷了，你就好好把手放在兜里，不要挥手，不要告别</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>MSRA DKI组实习研究员，UESTC三年级</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">4</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="http://garlicisnotmyfavor.xyz/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">garlic</span></span><span class="level-right"><span class="level-item tag">garlicisnotmyfavor.xyz</span></span></a></li><li><a class="level is-mobile" href="https://laolan-runtu.xyz" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">老兰</span></span><span class="level-right"><span class="level-item tag">laolan-runtu.xyz</span></span></a></li><li><a class="level is-mobile" href="https://blog.xtopia.fun/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">BANKRUPT</span></span><span class="level-right"><span class="level-item tag">blog.xtopia.fun</span></span></a></li><li><a class="level is-mobile" href="https://jiuchuan.top" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">葭萌</span></span><span class="level-right"><span class="level-item tag">jiuchuan.top</span></span></a></li><li><a class="level is-mobile" href="https://stardust567.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Star Trail</span></span><span class="level-right"><span class="level-item tag">stardust567.github.io</span></span></a></li><li><a class="level is-mobile" href="https://mtaun.top" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">mtaun</span></span><span class="level-right"><span class="level-item tag">mtaun.top</span></span></a></li><li><a class="level is-mobile" href="https://hexjacaranda.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">hexjacaranda</span></span><span class="level-right"><span class="level-item tag">hexjacaranda.github.io</span></span></a></li><li><a class="level is-mobile" href="https://browallia.top" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">browallia</span></span><span class="level-right"><span class="level-item tag">browallia.top</span></span></a></li><li><a class="level is-mobile" href="https://yijing233com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">yijing</span></span><span class="level-right"><span class="level-item tag">yijing233com</span></span></a></li><li><a class="level is-mobile" href="https://kevinello.ltd/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">kevinello</span></span><span class="level-right"><span class="level-item tag">kevinello.ltd</span></span></a></li><li><a class="level is-mobile" href="https://geminiplanet.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">GeminiPlanet</span></span><span class="level-right"><span class="level-item tag">geminiplanet.cn</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-22T11:37:00.000Z">2020-12-22</time></p><p class="title"><a href="/2020/12/22/How-Neural-Networks-Extrapolate/">How Neural Networks Extrapolate</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-22T06:55:51.000Z">2020-12-22</time></p><p class="title"><a href="/2020/12/22/Self-supervised-Learning-Generative-or-Contrastive/">Self-supervised Learning:Generative or Contrastive</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-21T12:43:55.000Z">2020-12-21</time></p><p class="title"><a href="/2020/12/21/Graph-information-bottleneck/">Graph information bottleneck</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-21T10:43:49.000Z">2020-12-21</time></p><p class="title"><a href="/2020/12/21/%E6%81%A9%E6%A0%BC%E6%96%AF%E3%81%AE%E6%80%92%E5%90%BC/">恩格斯の怒吼</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-21T10:15:24.000Z">2020-12-21</time></p><p class="title"><a href="/2020/12/21/%E8%8B%8F%E4%B8%9C%E5%9D%A1%E4%B8%8B%E7%9A%84%E5%88%AB%E8%87%B4%E4%BA%BA%E7%94%9F/">苏东坡下的别致人生</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2020/12/"><span class="level-start"><span class="level-item">December 2020</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/about-me/"><span class="tag">about me</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/information-bottleneck/"><span class="tag">information-bottleneck</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%BE%E5%86%85%E5%A4%8D%E4%B9%A0/"><span class="tag">课内复习</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">随笔</span><span class="tag">2</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="text:Queyue&#039;s Home" alt="Queyue" height="28"></a><p class="is-size-7"><span>&copy; 2020 Haitao Mao</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>